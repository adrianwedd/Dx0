phases:
  - name: "Phase 0: Engineering Foundation"
    tasks:
      - id: "T1"
        title: "Refactor VirtualPanel for Pluggable Decision Engines"
        description: >
          Replace the hard-coded keyword\u2192action mappings with a
          DecisionEngine interface. Provide both rule-based and LLM-based
          configuration.
        labels: [enhancement, refactor, backend]
        done: true
      - id: "T2"
        title: "Integrate Semantic Retrieval in Gatekeeper"
        description: >
          Use an embedding index (FAISS or similar) and retrieval-augmented
          generation for question answering. Fall back to regex search if the
          embedding step fails.
        labels: [enhancement, backend, ml]
        done: true
      - id: "T3"
        title: "Add Dynamic Test Result Handling"
        description: >
          Fetch realistic lab values from JSON fixtures instead of returning
          default results. Define the schema, implement a loader, and handle
          missing fixture errors.
        labels: [feature, backend, data]
        done: true
      - id: "T4"
        title: "Implement Detailed Logging & Metrics"
        description: >
          Add structured logging to the Orchestrator and Panel modules and
          expose a metrics endpoint for Prometheus. Provide example Grafana
          dashboard configuration.
        labels: [enhancement, observability, backend]
        done: true
      - id: "T5"
        title: "Expand Unit Tests for Error & Edge Cases"
        description: >
          Cover parsing errors, unknown inputs, and timeouts across core
          modules with comprehensive tests.
        labels: [test, quality, backend]
        done: true
      - id: "T6"
        title: "Enforce Code Style & Static Analysis"
        description: >
          Add Black, isort, flake8, and mypy checks via pre-commit and CI.
          Document installation steps for contributors.
        labels: [ci, quality, tooling]
        done: true
      - id: "T7"
        title: "Enhance CLI with Model & Config Flags"
        description: >
          Extend cli.py with flags for selecting the panel engine, LLM model,
          and logging verbosity.
        labels: [feature, cli, backend]
        done: true
      - id: "T8"
        title: "Modularize Prompt Templates & System Prompts"
        description: >
          Move all agent prompts into the prompts/ directory for easier
          versioning and A/B testing.
        labels: [enhancement, prompt-engineering, backend]
        done: true
      - id: "T9"
        title: "CI/CD Pipeline & Dockerization"
        description: >
          Add GitHub Actions workflows for tests and releases and create a
          Dockerfile for deployment.
        labels: [ci, docker, devops]
        done: true
      - id: "T10"
        title: "Update tasks.yml with Engineering Backlog"
        description: >
          Track the initial engineering tasks in this file.
        labels: [project-management, documentation]
        done: true
      - id: "T11"
        title: "Ingest & Convert NEJM CPC Cases for SDBench"
        description: >
          Build a pipeline to parse the 304 NEJM CPC articles and output
          SDBench-formatted JSON with summary, full text, and diagnosis.
        labels: [feature, data, backend]
        done: true
      - id: "T12"
        title: "Implement Gatekeeper with Synthetic Findings"
        description: >
          Create the Gatekeeper agent that mediates information requests and
          synthesizes plausible findings for unmentioned tests.
        labels: [feature, ai, backend]
        done: true
      - id: "T13"
        title: "Develop Judge Agent with Likert Rubric"
        description: >
          Implement the Judge agent using an LLM prompted with a 5-point
          clinical accuracy rubric to score diagnoses.
        labels: [feature, ai, evaluation]
        done: true
      - id: "T14"
        title: "Build Cost Estimator & CPT Mapper"
        description: >
          Translate test requests to CPT codes via LLM, map to CMS prices, and
          compute cumulative costs.
        labels: [feature, data, backend]
        done: true
      - id: "T15"
        title: "Create MAI-Dx Orchestrator & Virtual Panel"
        description: >
          Implement the orchestrator and the five-persona virtual panel
          running a chain-of-debate to produce actions.
        labels: [feature, agent-architecture, backend]
        done: true
      - id: "T16"
        title: "Support MAI-Dx Variants"
        description: >
          Enable Instant Answer, Question Only, Budgeted, Unconstrained
          Budget, and Ensemble modes via config.
        labels: [feature, backend, ml]
        done: true
      - id: "T17"
        title: "Build Physician UI for SDBench"
        description: >
          Provide a synchronous chat interface for physicians interacting with
          the Gatekeeper and Cost Estimator.
        labels: [feature, frontend, ux]
        done: true
      - id: "T18"
        title: "Implement Evaluation Pipeline & Reporting"
        description: >
          Automate simulation runs over all cases and generate accuracy and
          cost reports with Pareto plots.
        labels: [feature, analytics, backend]
        done: true
      - id: "T19"
        title: "Statistical Analysis & Significance Testing"
        description: >
          Provide permutation tests for evaluating accuracy improvements and
          expose a CLI entry point.
        labels: [feature, statistics, backend]
        done: true
      - id: "T20"
        title: "Document & Package SDBench for Release"
        description: >
          Package the benchmark as a Python distribution and supply
          documentation and licensing instructions.
        labels: [documentation, release, devops]
        done: true
      - id: "T21"
        title: "Automated Case Ingestion for Future Updates"
        description: >
          Design a framework to periodically scrape new NEJM CPC cases and
          integrate them into SDBench.
        labels: [feature, data, backend]
        done: true
      - id: "T22"
        title: "Legal & Licensing Review for Public Dataset"
        description: >
          Coordinate with legal to ensure the public release complies with
          NEJM permissions and licensing requirements.
        labels: [legal, compliance, project-management]
        done: true

  - name: "Phase 1: SDBench Framework and Environment Setup"
    tasks:
      - id: 1
        title: "Collect NEJM CPC cases"
        description: "Gather 304 consecutive CPC articles for dataset creation."
        done: true
      - id: 2
        title: "Convert cases to simulation format"
        description: "Transform each case into an interactive simulation with discrete steps."
        done: true
      - id: 3
        title: "Write summary for each case"
        description: "Provide a short synopsis highlighting the key features."
        done: true
      - id: 4
        title: "Create hidden test set"
        description: "Hold out 56 recent cases from 2024\u20132025 as a hidden evaluation set."
        done: true
      - id: 5
        title: "Lookup CPT codes with language model"
        description: "Translate test requests into CPT codes using an LLM."
        done: true
      - id: 6
        title: "Match codes to pricing table"
        description: "Achieve >98% coverage when mapping CPT codes to the pricing table."
        done: true
      - id: 7
        title: "Estimate costs for unmatched tests"
        description: "Use a language model to estimate prices when the table lacks an entry."
        done: true
      - id: 8
        title: "Apply visit fee"
        description: "Charge a fixed $300 cost for each physician visit."
        done: true
      - id: 9
        title: "Controlled Gatekeeper"
        description: "Implement Gatekeeper with controlled disclosure of case findings."
        done: true
      - id: 10
        title: "Refusal policy"
        description: "Gatekeeper must refuse vague queries and diagnostic impressions."
        done: true
      - id: 11
        title: "Synthetic results for off-path tests"
        description: "Generate synthetic results when the requested information is missing."
        done: true
      - id: 12
        title: "Judge agent with rubric"
        description: "Implement Judge agent that scores diagnoses with a 5-point rubric."
        done: true
      - id: 13
        title: "Define correct threshold"
        description: "Treat scores \u22654 from the judge as correct diagnoses."
        done: true

  - name: "Phase 2: MAI-DxO Agent Implementation and Execution"
    tasks:
      - id: 14
        title: "XML protocol"
        description: "Define <question>, <test>, and <diagnosis> messages for communication."
        done: true
      - id: 15
        title: "Enforce question/test separation"
        description: "Prohibit mixing questions and test orders in a single turn."
        done: true
      - id: 16
        title: "Create virtual panel"
        description: "Instantiate Dr. Hypothesis, Test-Chooser, Challenger, Stewardship, and Checklist personas."
        done: true
      - id: 17
        title: "Chain of Debate workflow"
        description: "Implement a sequential debate to decide the next action."
        done: true
      - id: 18
        title: "Unconstrained mode"
        description: "Run MAI-DxO without budget constraints."
        done: true
      - id: 19
        title: "Budgeted mode"
        description: "Track spending and enforce a budget limit."
        done: true
      - id: 20
        title: "Question Only and Instant Answer"
        description: "Support streamlined modes that limit or skip the debate."
        done: true
      - id: 21
        title: "Ensemble variant"
        description: "Combine multiple MAI-DxO runs to produce a final answer."
        done: true
      - id: 22
        title: "Evaluation"
        description: "Use the Judge agent to score the final diagnosis and compute cost."
        done: true
      - id: 23
        title: "Plot accuracy vs cost"
        description: "Visualize trade-offs by plotting the Pareto frontier."
        done: true

  - name: "Phase 3: Production Readiness & Advanced Features"
    tasks:
      - id: "T23"
        title: "Fully Implement and Tune LLM-Based Decision Engine"
        description: >
          Replace the placeholder LLMEngine with a fully functional, prompt-driven engine. This involves creating and validating the persona-specific prompts required for the "Chain of Debate" and ensuring the model's output can be reliably parsed.
        labels: [feature, ai, backend, prompt-engineering]
        subtasks:
          - "Develop and test the system prompt for the **Dr. Hypothesis** agent to generate a differential diagnosis based on initial case findings."
          - "Implement and validate the prompt for the **Dr. Test-Chooser** agent to select the most discriminative tests or questions."
          - "Create and refine the adversarial prompt for the **Dr. Challenger** agent to identify biases and propose alternative paths."
          - "Develop the cost-aware prompt for the **Dr. Stewardship** agent to analyze the cost-benefit of proposed tests."
          - "Implement a final prompt for the **Dr. Checklist** agent to ensure completeness and consistency before an action is taken."
          - "Create robust parsing logic to handle the LLM's output and convert it into a structured `PanelAction`."
        done: true
      - id: "T24"
        title: "Integrate Semantic Search into Gatekeeper"
        description: >
          Upgrade the Gatekeeper's question-answering capability from keyword search to a modern retrieval-augmented generation (RAG) pipeline for more accurate and context-aware responses.
        labels: [enhancement, backend, ml]
        subtasks:
          - "Select an appropriate sentence-transformer model for creating high-quality embeddings of medical text."
          - "Build a script to pre-process and create a vector index (e.g., using FAISS or a similar library) for all 304 NEJM case documents."
          - "Modify the `Gatekeeper.answer_question` method to first query the vector index to retrieve relevant text chunks."
          - "Implement a RAG prompt that combines the user's question with the retrieved chunks to generate a precise answer using an LLM."
          - "Establish a fallback mechanism to use the old regex search if the semantic search fails to return relevant results."
        done: true

      - id: "T25"
        title: "Build Interactive Physician UI for SDBench"
        description: >
          Develop a web-based user interface that allows human physicians to participate in SDBench challenges, providing a benchmark for human performance and a tool for data collection.
        labels: [feature, frontend, ux]
        subtasks:
          - "Design a clean, synchronous chat interface using a modern web framework (e.g., React, Vue, or Svelte)."
          - "Create a backend API (e.g., using Flask or FastAPI) to connect the frontend to the `Orchestrator`."
          - "Implement WebSocket support for real-time, turn-by-turn interaction between the physician and the `Gatekeeper`."
          - "Add a user authentication system to manage physician accounts and track their performance over time."
          - "Display the cumulative cost from the `CostEstimator` in the UI, updating it in real-time as tests are ordered."
          - "Ensure the interface is intuitive and requires minimal training for physicians to use effectively."
        done: true

      - id: "T26"
        title: "Enhance Orchestrator for Advanced Ensemble Strategies"
        description: >
          Improve the `Ensemble` mode by implementing more sophisticated aggregation and meta-panel strategies to boost diagnostic accuracy beyond simple majority voting.
        labels: [enhancement, agent-architecture, ml]
        subtasks:
          - "Implement a weighted voting mechanism based on the confidence scores or internal consistency of each parallel panel."
          - "Develop a 'Meta-Panel' agent that reviews the diagnoses and reasoning chains from all parallel runs to produce a final, synthesized diagnosis."
          - "Explore cost-adjusted utility functions to select a final diagnosis that optimizes for both accuracy and cost-effectiveness."
        done: true

  - name: "Phase 4: LLM Integration and Production Hardening"
    tasks:
      - id: "T27"
        title: "Implement Multi-Provider LLM Engine for Panel"
        description: >
          Refactor the LLMEngine to be provider-agnostic, with initial support for the OpenAI API and local Ollama models. This is critical for flexibility and cost management in production.
        labels: [feature, ai, backend, refactor]
        subtasks:
          - "Design a generic `LLMClient` interface that standardizes methods for chat completions and managing API credentials."
          - "Implement an `OpenAIClient` that conforms to the interface and handles communication with the OpenAI API, including API key management."
          - "Implement an `OllamaClient` that conforms to the interface and communicates with a local Ollama server endpoint."
          - "Update the `LLMEngine` to accept a configured client (OpenAI or Ollama) during initialization."
          - "Extend the main CLI with `--llm-provider` (choices: openai, ollama) and `--llm-model` flags to allow runtime selection of the desired model."
        done: true

      - id: "T28"
        title: "Production-Grade Logging and Monitoring"
        description: >
          Enhance the existing logging and metrics system to provide the visibility needed to operate, debug, and optimize the system in a production environment.
        labels: [enhancement, observability, backend]
        subtasks:
          - "Implement structured (JSON-formatted) logging across all major components to enable easier parsing and analysis by log aggregation platforms."
          - "Add detailed performance metrics, including LLM query latency, token usage per turn, and estimated cost per query (for OpenAI)."
          - "Create a comprehensive Grafana dashboard configuration for visualizing key operational metrics, such as case processing time, agent accuracy, and token consumption."
        done: true

      - id: "T29"
        title: "Finalize Documentation and Packaging for Release"
        description: >
          Prepare the project for its first official public release by improving documentation, creating a distributable package, and ensuring legal compliance.
        labels: [documentation, release, devops]
        subtasks:
          - "Write comprehensive user documentation detailing how to set up the environment for both OpenAI and local Ollama usage."
          - "Create a `pyproject.toml` file and ensure the project can be cleanly packaged into a wheel (`.whl`) and source distribution (`.tar.gz`)."
          - "Perform a final review of the README, CONTRIBUTING, and LICENSE files to ensure they are clear and complete."
        done: true

      - id: "T30"
        title: "Refactor Judge Agent for Robustness"
        description: >
          Improve the Judge agent by moving beyond simple string similarity to a more robust, LLM-based evaluation to better handle clinical nuance and synonyms.
        labels: [enhancement, ai, evaluation]
        subtasks:
          - "Replace the `difflib.SequenceMatcher` in the `Judge` class with a call to a configured LLM."
          - "Develop a precise prompt for the Judge LLM that instructs it to compare the candidate and ground-truth diagnoses based on clinical substance, not just lexical similarity, using the 5-point rubric."
          - "Add unit tests to `test_judge.py` to validate the new LLM-based evaluation logic with a variety of clinically similar but lexically different diagnostic pairs."
        done: true

      - id: "T31"
        title: "Automate Case Updates"
        description: >
          Schedule a weekly workflow that fetches newly released NEJM CPC cases
          and appends them to the dataset. The script skips already ingested
          PMIDs to avoid duplicates.
        labels: [automation, data]
        done: true

      - id: "T32"
        title: "Cache LLM Responses"
        description: >
          Store completions from the LLM engine on disk to avoid
          duplicate API calls and reduce cost.
        labels: [enhancement, backend, optimization]
        actionable_steps:
          - "Design a caching strategy balancing performance and data freshness."
          - "Implement the cache in `LLMClient` with optional CLI flag to enable it."
          - "Write unit tests covering cache hits and evictions."
        acceptance_criteria:
          - "Average latency of LLM requests is reduced by at least 30%."
          - "API calls to the provider drop by at least 40%."
        done: true
      - id: "T33"
        title: "FHIR Export for Sessions"
        description: >
          Output orchestrator transcripts and ordered tests in a
          FHIR-compatible format for integration with clinical systems.
        labels: [feature, interoperability]
        done: true
      - id: "T34"
        title: "Dataset Versioning with DVC"
        description: >
          Track case data and embeddings using DVC to enable
          reproducible experiments.
        labels: [tooling, data]
        done: true
      - id: "T35"
        title: "Continuous Packaging Workflow"
        description: >
          Publish wheels to PyPI from CI when tagging a release.
        labels: [ci, release]
        done: true
      - id: "T36"
        title: "Cross-Encoder Re-Ranking"
        description: >
          Improve semantic retrieval by re-ranking top passages
          with a cross-encoder model for higher precision.
        labels: [enhancement, ml]
        done: true

      - id: "T37"
        title: "Automatic CMS Pricing Updates"
        description: >
          Provide a script that fetches the latest CMS pricing table
          and refreshes the local cost database.
        labels: [automation, data]
        done: true

      - id: "T38"
        title: "FHIR Case Import"
        description: >
          Add utilities to convert FHIR diagnostic reports and
          observations into the internal SDBench case format.
        labels: [feature, interoperability]
        done: true

      - id: "T39a"
        title: "Asynchronous Batch Evaluation"
        description: >
          Run large-scale case evaluations concurrently to reduce
          turnaround time on shared compute clusters.
        labels: [enhancement, performance]
        done: true


      - id: "T40"
        title: "Asynchronous Batch Evaluation CLI"
        description: >
          Add a `batch-eval` subcommand that evaluates multiple cases concurrently
          and writes aggregated CSV results.
        labels: [feature, cli, evaluation]
        done: true

      - id: "T41"
        title: "Expand CPT Code Lookup Table"
        description: >
          Reduce reliance on the LLM for pricing by expanding the built-in mapping
          of common medical tests to CPT codes and CMS prices.
        labels: [data, enhancement]
        actionable_steps:
          - "Identify frequently ordered tests in the case data."
          - "Research corresponding CPT codes and current prices."
          - "Add at least 100 new entries to `cpt_lookup.csv`."
        acceptance_criteria:
          - "`cpt_lookup.csv` contains the new codes."
          - "LLM CPT lookups decrease by 20%."
        done: true

      - id: "T42"
        title: "Improve Rule-Based Decision Engine"
        description: >
          Extend `sdb/decision.py` with additional clinical rules to boost accuracy
          of the non-LLM engine.
        labels: [ai, backend]
        actionable_steps:
          - "Analyze common diagnostic misses with the current engine."
          - "Add rules considering more clinical variables."
          - "Document new logic within `RuleEngine`."
          - "Expand rules to cover headaches, sore throat and dizziness."
        done: true
        acceptance_criteria:
          - "Rule-based accuracy improves by 10%."

      - id: "T43"
        title: "Refine LLM Prompts"
        description: >
          Improve the prompts used by the LLM-based engine to reduce errors and
          make maintenance easier.
        labels: [ai, prompt-engineering]
        actionable_steps:
          - "Review common LLM mistakes and adjust instructions."
          - "A/B test revised prompts for effectiveness."
        acceptance_criteria:
          - "Error rate drops by 15%."
        done: true

      - id: "T44"
        title: "Enhance Web UI"
        description: >
          Provide a clearer case summary, test history, and a visual diagram of the
          diagnostic process.
        done: true
        labels: [frontend, ux]
        actionable_steps:
          - "Add summary and ordered-test panels."
          - "Draw the system's diagnostic path graphically."
          - "Improve layout styling for readability."
        acceptance_criteria:
          - "New features are functional and intuitive."

- id: 45
  title: Secure Web UI Authentication
  description: >
    Replace the hardcoded credential store in `sdb/ui/app.py` with a
    configuration-based approach using hashed passwords. Credentials should be
    loaded from environment variables or an external file and verified using a
    secure hashing algorithm. Add tests covering authentication success and
    failure cases.
  component: ui
  area: security
  dependencies: []
  priority: 1
  status: done
  actionable_steps:
    - Remove the `USERS` dict from the codebase.
    - Load user credentials from a config file or environment variable.
    - Store and verify passwords using a strong hash (e.g., bcrypt).
    - Update login logic and add unit tests.
  acceptance_criteria:
    - "No plaintext passwords remain in the repository."
    - "Login succeeds with valid credentials and fails otherwise."
  command: null
  epic: Phase 5
  assigned_to: null

- id: 55
  title: Add Async LLM Client Support
  description: >
    Implement asynchronous LLM client and concurrency utilities for batch
    evaluation.
  component: backend
  area: async
  dependencies: []
  priority: 4
  status: done
  actionable_steps:
    - Provide `AsyncLLMClient` with async chat method.
    - Allow `LLMEngine` and helpers to use async clients.
    - Run LLM calls concurrently during batch evaluation.
  acceptance_criteria:
    - "Async batch evaluation functions handle coroutine case runners."
  command: null
  epic: Phase 5
  assigned_to: null

- id: 46
  title: Centralize Application Configuration
  description: >
    Introduce a Pydantic-based configuration schema loaded from a YAML file.
    The CLI should accept a `--config` flag to specify the config path, and all
    modules should access settings via this centralized object.
  component: cli
  area: configuration
  dependencies: []
  priority: 3
  status: done
  actionable_steps:
    - Define `Settings` dataclass or Pydantic model.
    - Load settings from YAML at startup.
    - Refactor modules to read values from the settings object.
    - Document the configuration options.
  acceptance_criteria:
    - "CLI runs with --config and values propagate to orchestrator."
    - "Default configuration file documented in README."
  command: null
  epic: Phase 5
  assigned_to: null

- id: 47
  title: Add Async LLMClient for Concurrent Calls
  description: >
    Implement an asynchronous variant of `LLMClient` so batch evaluations can
    perform concurrent LLM requests without blocking the event loop. Update the
    orchestrator and evaluator as needed to support async operation.
  component: backend
  area: performance
  dependencies: []
  priority: 2
  status: done
  actionable_steps:
    - Create `AsyncLLMClient` with async `chat` method.
    - Update `LLMEngine` and evaluation helpers to use async when provided.
    - Add tests for concurrent execution path.
  acceptance_criteria:
    - "Batch evaluations run asynchronously without errors."
    - "Performance improves when using async client."
  command: null
  epic: Phase 5
  assigned_to: null

- id: 48
  title: Harden Gatekeeper Query Parsing
  description: >
    Improve XML parsing in `Gatekeeper.answer_question` by validating against a
    strict schema and sanitizing inputs to prevent malformed or malicious
    queries. Return clear error messages on validation failures.
  component: gatekeeper
  area: security
  dependencies: []
  priority: 2
  status: done
  actionable_steps:
    - Define an XML schema for allowed queries.
    - Validate incoming XML against the schema.
    - Add tests for malformed and malicious inputs.
  acceptance_criteria:
    - "Gatekeeper rejects invalid XML with informative errors."
    - "All new tests pass."
  command: null
  epic: Phase 5
  assigned_to: null

- id: 49
  title: Standardize Structured Logging
  description: >
    Replace ad-hoc logging calls with a unified structured logging framework
    (e.g., `structlog`). Ensure all modules log consistent fields and severity
    levels for easier monitoring.
  component: backend
  area: observability
  dependencies: []
  priority: 4
  status: done
  actionable_steps:
    - Integrate `structlog` and configure JSON output.
    - Refactor existing `logger` calls across modules.
    - Update documentation on log consumption.
  acceptance_criteria:
    - "Logs are JSON-formatted and include module, level, and message." 
    - "No remaining plain `print` or inconsistent logger usage." 
  command: null
  epic: Phase 5
  assigned_to: null

- id: 50
  title: Plugin System for Panel Personas
  description: >
    Allow custom persona chains to be loaded as plugins so researchers can
    experiment with alternative agent roles without modifying core code.
  component: panel
  area: architecture
  dependencies: []
  priority: 5
  status: done
  actionable_steps:
    - Define entry point mechanism for persona plugins.
    - Load persona definitions dynamically at runtime.
    - Provide example plugin and documentation.
  acceptance_criteria:
    - "New personas can be added via plugin without touching core modules."
  command: null
  epic: Phase 5
  assigned_to: null

- id: 51
  title: Expand Test Coverage for Web UI and Async Evaluation
  description: >
    Add integration tests exercising the FastAPI WebSocket endpoints and the
    asynchronous batch evaluation helpers to prevent regressions.
  component: tests
  area: testing
  dependencies: [47]
  priority: 3
  status: done
  actionable_steps:
    - Use `httpx.AsyncClient` to test WebSocket flows.
    - Add tests validating concurrency limits in `async_batch_evaluate`.
  acceptance_criteria:
    - "CI runs new tests successfully."
  command: null
  epic: Phase 5
  assigned_to: null

- id: 52
  title: Switch Embedding Index to FAISS
  description: >
    Replace the custom `SentenceTransformerIndex` backend with FAISS for faster
    and more memory-efficient retrieval when indexing the full CPC dataset.
  component: retrieval
  area: performance
  dependencies: []
  priority: 4
  status: done
  actionable_steps:
    - Add FAISS as an optional dependency.
    - Implement FAISS-backed index class.
    - Provide migration guide for existing embeddings.
  acceptance_criteria:
    - "Retrieval latency decreases on large datasets." 
  command: null
  epic: Phase 5
  assigned_to: null

- id: 53
  title: Pin Dependency Versions and Document Updates
  description: >
    Pin exact dependency versions in `requirements-dev.txt` and document a
    process for regular security updates using tools like `pip-audit`.
  component: build
  area: dependencies
  dependencies: []
  priority: 4
  status: done
  actionable_steps:
    - Update requirements files with version pins.
    - Add a docs section on updating and auditing dependencies.
  acceptance_criteria:
    - "`pip install -r requirements-dev.txt` yields deterministic versions."
  command: null
  epic: Phase 5
  assigned_to: null

- id: 54
  title: Make LLM FileCache Thread-Safe
  description: >
    Protect the JSONL cache used by `LLMClient` with file locks to avoid
    corruption when multiple threads or processes access it concurrently.
  component: backend
  area: robustness
  dependencies: []
  priority: 3
  status: done
  actionable_steps:
    - Add a cross-platform file lock around cache read/write.
    - Write tests simulating concurrent access.
  acceptance_criteria:
    - "Concurrent LLM calls do not corrupt the cache file."
  command: null
  epic: Phase 5
  assigned_to: null
